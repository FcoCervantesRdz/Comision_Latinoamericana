{"cells":[{"cell_type":"markdown","metadata":{"id":"0Ul1drlC6R7G"},"source":["## Conexion a BigQuery"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"dDuTA7Hl65pV"},"outputs":[],"source":["from google.cloud import bigquery\n","from google.oauth2 import service_account\n","import pandas as pd\n","pd.options.mode.chained_assignment = None #ignora warnings\n","import Levenshtein as lev"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["def extraer_tablas():\n","  credentials = service_account.Credentials.from_service_account_file('tidy-hold-359719-964ba4f0d1d8.json') #credenciales\n","  project_id = 'tidy-hold-359719' #nombre del proyecto\n","  client = bigquery.Client(credentials= credentials,project=project_id) #creo cliente\n","  dataset_ref = client.dataset(\"proyecto\", project=project_id) #referencia al dataset\n","  dataset = client.get_dataset(dataset_ref) #dataset\n","  #QUERYS\n","  q_NDC=\"\"\"SELECT * FROM `tidy-hold-359719.proyecto.NDC`\"\"\"   #query para tabla NDC\n","  \n","  q_datos_ONU = \"\"\"                              \n","    SELECT a.GeoAreaName as Pais,\n","    a.TimePeriod as Anio,\n","    a.Value as intensidad_energetica_medida_en_terminos_de_energia_primaria_y_PBI,\n","    b.Value as proporcion_de_la_poblacion_con_acceso_a_elecricidad,\n","    c.Value as proporcion_de_la_poblacion_con_dependencia_primaria_a_energias_limpias,\n","    d.Value as proporcion_de_energias_renovables_del_total_consumido,\n","    FROM `tidy-hold-359719.proyecto.energy_intensity_measured_in_terms_of_primary_energy_and_GDP` a\n","    LEFT JOIN `tidy-hold-359719.proyecto.proportion_of_population_with_access_to_electricity` b ON (a.GeoAreaName=b.GeoAreaName and a.TimePeriod = b.TimePeriod) AND b.Location='ALLAREA'\n","    LEFT JOIN `tidy-hold-359719.proyecto.proportion_of_population_with_primary_reliance_on_clean_fuels_and_technology` c ON (a.GeoAreaName=c.GeoAreaName and a.TimePeriod = c.TimePeriod)\n","    LEFT JOIN `tidy-hold-359719.proyecto.renewable_energy_share_in_the_total_final_energy_consumption` d ON (a.GeoAreaName=d.GeoAreaName and a.TimePeriod = d.TimePeriod)\n","    \"\"\"\n","  q_energyco2 = \"\"\"\n","    SELECT Country AS Pais, \n","           Year AS Anio, \n","           CO2_emission AS Emisiones_de_CO2,\n","           Energy_consumption AS Consumo_energia,\n","\t         Energy_production AS Produccion_energia, \n","           GDP AS PBI,\n","           Population AS Poblacion,\n","           Energy_intensity_per_capita AS Intencidad_per_capita,\n","           Energy_intensity_by_GDP AS Intensidad_por_PBI\n","    FROM `tidy-hold-359719.proyecto.energyco2`\n","    WHERE Energy_type = 'all_energy_types'\n","    \"\"\"\n","  \n","  q_Temperaturas = \"\"\"\n","    SELECT * FROM `tidy-hold-359719.proyecto.temperaturas`\n","    \"\"\"\n","\n","  q_porcentaje_compromiso = \"\"\"\n","    SELECT * FROM `tidy-hold-359719.proyecto.porcentraje_compromiso`\n","    \"\"\"\n","  NDC = client.query(q_NDC).to_dataframe() #dataframe de NDC\n","  datos_ONU = client.query(q_datos_ONU).to_dataframe() #dataframe de datos onu\n","  energyco2 = client.query(q_energyco2).to_dataframe() \n","  temperaturas = client.query(q_Temperaturas).to_dataframe()\n","  porcentaje_compromiso = client.query(q_porcentaje_compromiso).to_dataframe()  \n","  return NDC,datos_ONU,energyco2,temperaturas,porcentaje_compromiso\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["def traductor(df):\n","  for i in range(len(df)):\n","    for j in range(len(NDC)):\n","        if lev.ratio(df.Pais[i], NDC.Pais[j]) > 0.8:\n","            df.Pais[i]= NDC.Pais[j]\n","  df.loc[df.Pais=='World', 'Pais']='Mundo'\n","  df.loc[df.Pais=='United States', 'Pais']='Estados Unidos'\n","  df.loc[df.Pais=='Dominican Republic', 'Pais']='República Dominicana'\n","  df.loc[df.Pais=='Saint Kitts and Nevis', 'Pais']='San Cristóbal y Nieves'\n","  df.loc[df.Pais=='Peru', 'Pais']='Perú'\n","  df.loc[df.Pais=='Haiti', 'Pais']='Haití'\n","  return df"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["#defino otro traductor pq ONU tiene otros nombres\n","def traductor_ONU(df):\n","  for i in range(len(df)):\n","    for j in range(len(NDC)):\n","        if lev.ratio(df.Pais[i], NDC.Pais[j]) > 0.8:\n","            df.Pais[i]= NDC.Pais[j]\n","  df.loc[df.Pais=='World', 'Pais']='Mundo'\n","  df.loc[df.Pais=='United States', 'Pais']='Estados Unidos'\n","  df.loc[df.Pais=='Dominican Republic', 'Pais']='República Dominicana'\n","  df.loc[df.Pais=='Saint Kitts and Nevis', 'Pais']='San Cristóbal y Nieves'\n","  df.loc[df.Pais=='Peru', 'Pais']='Perú'\n","  df.loc[df.Pais=='Haiti', 'Pais']='Haití'\n","  df.loc[df.Pais=='Bolivia (Plurinational State of)', 'Pais']='Bolivia'\n","  df.loc[df.Pais=='Venezuela (Bolivarian Republic of)', 'Pais']='Venezuela'\n","  return df"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["def filtro_latam(df):\n","  df = df[df.Pais.isin(NDC.Pais.unique().tolist())]\n","  df.reset_index(drop=True, inplace=True)\n","  return df"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["def carga(df):\n","  credentials = service_account.Credentials.from_service_account_file('tidy-hold-359719-964ba4f0d1d8.json') #credenciales\n","  project_id = 'tidy-hold-359719' #nombre del proyecto\n","  client = bigquery.Client(credentials= credentials,project=project_id) #creo cliente\n","  table_id = \"tidy-hold-359719.comision_latinoamericana_alicia.\"+[ k for k,v in globals().items() if v is df][0]\n","  #configuracion de la carga\n","  job_config = bigquery.LoadJobConfig(write_disposition=\"WRITE_TRUNCATE\")\n","  job = client.load_table_from_dataframe(df, table_id, job_config=job_config)  \n","  # Make an API request.\n","  job.result()  # Wait for the job to complete.\n","  table = client.get_table(table_id)  # Make an API request.\n","  print(\"Cargadas {} filas y {} columnas a {}\".format(table.num_rows, len(table.schema), table_id))\n","\n","def nans(df):\n","  df.fillna(-1,inplace=True) #nan con -1 para despues filtrarlos\n","def erroneos(df):\n","  df.replace({'>95':96,'NaN':-1,'<5':4},inplace=True)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["NDC, datos_ONU, energyco2,temperaturas,porcentaje_compromiso = extraer_tablas()\n","\n","\n","NDC.rename(columns={'string_field_0':'Pais'},inplace=True)\n","\n","\n","temperaturas.columns=['Anio', 'Temperatura', 'Cod_Pais']"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Loaded 3872 rows and 3 columns to tidy-hold-359719.comision_latinoamericana_alicia.temperatura\n"]}],"source":["\n","#carga de temperatura\n","credentials = service_account.Credentials.from_service_account_file('tidy-hold-359719-964ba4f0d1d8.json') #credenciales\n","project_id = 'tidy-hold-359719' #nombre del proyecto\n","client = bigquery.Client(credentials= credentials,project=project_id) #creo cliente\n","table_id = \"tidy-hold-359719.comision_latinoamericana_alicia.temperatura\"\n","job_config = bigquery.LoadJobConfig(\n","    # Specify a (partial) schema. All columns are always written to the\n","    # table. The schema is used to assist in data type definitions.\n","    #schema=[\n","        # Specify the type of columns whose type cannot be auto-detected. For\n","        # example the \"title\" column uses pandas dtype \"object\", so its\n","        # data type is ambiguous.\n","        #bigquery.SchemaField(\"Anio\", bigquery.enums.SqlTypeNames.DATE)\n","        # Indexes are written if included in the schema by name.\n","    #    bigquery.SchemaField(\"Pais\", bigquery.enums.SqlTypeNames.DATE)\n","    #],\n","    # Optionally, set the write disposition. BigQuery appends loaded rows\n","    # to an existing table by default, but with WRITE_TRUNCATE write\n","    # disposition it replaces the table with the loaded data.\n","    write_disposition=\"WRITE_TRUNCATE\"\n",")\n","\n","job = client.load_table_from_dataframe(\n","    temperaturas, table_id, job_config=job_config\n",")  # Make an API request.\n","job.result()  # Wait for the job to complete.\n","\n","table = client.get_table(table_id)  # Make an API request.\n","print(\n","    \"Loaded {} rows and {} columns to {}\".format(\n","        table.num_rows, len(table.schema), table_id\n","    )\n",")"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Cargadas 640 filas y 6 columnas a tidy-hold-359719.comision_latinoamericana_alicia.datos_ONU\n","Cargadas 1280 filas y 9 columnas a tidy-hold-359719.comision_latinoamericana_alicia.energyco2\n"]}],"source":["# FILTRO Y CARGA DATOS ONU\n","\n","datos_ONU = traductor_ONU(datos_ONU)\n","datos_ONU = filtro_latam(datos_ONU)\n","nans(datos_ONU)\n","erroneos(datos_ONU)\n","datos_ONU['proporcion_de_la_poblacion_con_dependencia_primaria_a_energias_limpias'] = pd.to_numeric(datos_ONU['proporcion_de_la_poblacion_con_dependencia_primaria_a_energias_limpias'])\n","carga(datos_ONU)\n","\n","\n","# FILTRO Y CARGA DE ENERGY CO2\n","energyco2 = traductor(energyco2)\n","energyco2 = filtro_latam(energyco2)\n","nans(energyco2)\n","erroneos(energyco2)\n","carga(energyco2)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Loaded 32 rows and 3 columns to tidy-hold-359719.comision_latinoamericana_alicia.compromiso\n","** CARGA DE DATOS COMPLETA**\n"]}],"source":["#PORCENTAJE COMPROMISO\n","\n","\n","porcentaje_compromiso.columns=['Pais', 'Cod_Pais', 'Compromiso']\n","#carga de porcentaje compromiso\n","\n","credentials = service_account.Credentials.from_service_account_file('tidy-hold-359719-964ba4f0d1d8.json') #credenciales\n","project_id = 'tidy-hold-359719' #nombre del proyecto\n","client = bigquery.Client(credentials= credentials,project=project_id) #creo cliente\n","table_id = \"tidy-hold-359719.comision_latinoamericana_alicia.compromiso\"\n","job_config = bigquery.LoadJobConfig(\n","    # Specify a (partial) schema. All columns are always written to the\n","    # table. The schema is used to assist in data type definitions.\n","    #schema=[\n","        # Specify the type of columns whose type cannot be auto-detected. For\n","        # example the \"title\" column uses pandas dtype \"object\", so its\n","        # data type is ambiguous.\n","        #bigquery.SchemaField(\"Anio\", bigquery.enums.SqlTypeNames.DATE)\n","        # Indexes are written if included in the schema by name.\n","    #    bigquery.SchemaField(\"Pais\", bigquery.enums.SqlTypeNames.DATE)\n","    #],\n","    # Optionally, set the write disposition. BigQuery appends loaded rows\n","    # to an existing table by default, but with WRITE_TRUNCATE write\n","    # disposition it replaces the table with the loaded data.\n","    write_disposition=\"WRITE_TRUNCATE\"\n",")\n","\n","job = client.load_table_from_dataframe(\n","    porcentaje_compromiso, table_id, job_config=job_config\n",")  # Make an API request.\n","job.result()  # Wait for the job to complete.\n","\n","table = client.get_table(table_id)  # Make an API request.\n","print(\n","    \"Loaded {} rows and {} columns to {}\".format(\n","        table.num_rows, len(table.schema), table_id\n","    )\n",")\n","\n","\n","\n","print('** CARGA DE DATOS COMPLETA**')"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"Copia de conexion_big_query_python.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3.10.4 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"vscode":{"interpreter":{"hash":"4f32d63f9d9db13e564df6c5cb9e6c17ef77e8d0920b01224c6a637534aac612"}}},"nbformat":4,"nbformat_minor":0}
